{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/israinamdar493-ops/retinalprojectsizz4/blob/main/Retinalai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zs8re2pbFoKX",
        "outputId": "e8f0231a-4ca2-4789-f93a-a9229a95f9b0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 4044.65it/s]\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "input_folder = '/content/drive/MyDrive/retinalnewproject/datasets/odir5k'\n",
        "output_folder = '/content/drive/MyDrive/retinalnewproject/outputs'\n",
        "\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "for file in tqdm(os.listdir(input_folder)):\n",
        "    if file.endswith(\".jpg\") or file.endswith(\".png\"):\n",
        "        img = cv2.imread(os.path.join(input_folder, file))\n",
        "        img_resized = cv2.resize(img, (512,512))\n",
        "        cv2.imwrite(os.path.join(output_folder, file), img_resized)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uu92Byhlwri5"
      },
      "outputs": [],
      "source": [
        "# Example: read image and normalize\n",
        "img = cv2.imread('/content/drive/MyDrive/retinalnewproject/datasets/odir5k/datasets/ageDegeneration/image0.png')\n",
        "img_normalized = img / 255.0  # now pixel values are between 0 and 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WawGv4FCznEI"
      },
      "outputs": [],
      "source": [
        "def augment_image(img):\n",
        "    import cv2\n",
        "    import numpy as np\n",
        "\n",
        "    # 1. Horizontal flip\n",
        "    img_flip = cv2.flip(img, 1)\n",
        "\n",
        "    # 2. Rotation (90 degrees)\n",
        "    img_rot = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
        "\n",
        "    # 3. CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
        "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
        "    l, a, b = cv2.split(lab)\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "    cl = clahe.apply(l)\n",
        "    lab_clahe = cv2.merge((cl,a,b))\n",
        "    img_clahe = cv2.cvtColor(lab_clahe, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    return [img_flip, img_rot, img_clahe]\n",
        "\n",
        "# Example usage\n",
        "augmented_images = augment_image(img)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5pJnBhVzsv9",
        "outputId": "7179078f-3142-4ad0-bae1-f57888d7114c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 3057.07it/s]\n"
          ]
        }
      ],
      "source": [
        "for file in tqdm(os.listdir(input_folder)):\n",
        "    if file.endswith(\".jpg\") or file.endswith(\".png\"):\n",
        "        img = cv2.imread(os.path.join(input_folder, file))\n",
        "        aug_imgs = augment_image(img)\n",
        "        # Save augmented images\n",
        "        for i, aug in enumerate(aug_imgs):\n",
        "            filename = file.split('.')[0] + f'_aug{i}.jpg'\n",
        "            cv2.imwrite(os.path.join(output_folder, filename), aug)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMoJn8g60NwW",
        "outputId": "30e42034-fb17-46ca-8152-d03306d0d8f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing ODIR5K...\n",
            "✅ Finished ODIR5K\n",
            "\n",
            "Processing RFMiD...\n",
            "✅ Finished RFMiD\n",
            "\n",
            "Processing APTOS...\n",
            "✅ Finished APTOS\n",
            "\n",
            "Processing Messidor2...\n",
            "✅ Finished Messidor2\n",
            "\n",
            "Processing DRIVE...\n",
            "✅ Finished DRIVE\n",
            "\n",
            "Processing CHASEDB1...\n",
            "✅ Finished CHASEDB1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import cv2, os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Your dataset names\n",
        "DATASETS = ['ODIR5K', 'RFMiD', 'APTOS', 'Messidor2', 'DRIVE', 'CHASEDB1']\n",
        "\n",
        "# Set paths\n",
        "base_path = \"/content/drive/MyDrive/retinalnewproject/datasets\"\n",
        "output_base = \"/content/drive/MyDrive/retinalnewproject/preprocessing\"\n",
        "resize_dim = (512, 512)  # Resize to 512x512\n",
        "\n",
        "def augment_image(img):\n",
        "    \"\"\"Basic data augmentation\"\"\"\n",
        "    aug_list = []\n",
        "    aug_list.append(cv2.flip(img, 1))                        # Horizontal flip\n",
        "    aug_list.append(cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)) # Rotate 90\n",
        "    return aug_list\n",
        "\n",
        "def preprocess_dataset(dataset):\n",
        "    input_folder = os.path.join(base_path, dataset)\n",
        "    output_folder = os.path.join(output_base, dataset)\n",
        "\n",
        "    if not os.path.exists(input_folder):\n",
        "        print(f\"⚠️ Skipping {dataset}: Input folder not found.\")\n",
        "        return\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    print(f\"Processing {dataset}...\")\n",
        "\n",
        "    # ✅ This walks through all subfolders to find images\n",
        "    for root, _, files in os.walk(input_folder):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
        "                img_path = os.path.join(root, file)\n",
        "                img = cv2.imread(img_path)\n",
        "\n",
        "                if img is None:  # Skip if image can't be read\n",
        "                    continue\n",
        "\n",
        "                # Resize and normalize\n",
        "                img_resized = cv2.resize(img, resize_dim)\n",
        "                img_normalized = img_resized / 255.0\n",
        "\n",
        "                # Save resized image\n",
        "                save_path = os.path.join(output_folder, file)\n",
        "                cv2.imwrite(save_path, (img_normalized * 255).astype(np.uint8))\n",
        "\n",
        "                # Data augmentation\n",
        "                for i, aug in enumerate(augment_image(img_resized)):\n",
        "                    aug_name = file.split('.')[0] + f'_aug{i}.jpg'\n",
        "                    cv2.imwrite(os.path.join(output_folder, aug_name), aug)\n",
        "\n",
        "    print(f\"✅ Finished {dataset}\\n\")\n",
        "\n",
        "# Run preprocessing for all datasets\n",
        "for dataset in DATASETS:\n",
        "    preprocess_dataset(dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8q0gJ_K9ckyg",
        "outputId": "21b38260-6c6d-4047-d0e8-9cde021dd72b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files inside ODIR5K: ['test.csv', 'train_1.csv', 'valid.csv', 'val_images', 'train_images', 'test_images']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "path = \"/content/drive/MyDrive/retinalnewproject/datasets/APTOS\"\n",
        "print(\"Files inside ODIR5K:\", os.listdir(path))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a52AMU8AgTuG",
        "outputId": "6f4456cd-7b58-4456-8562-43a3bafb9a8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing APTOS/train_images...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 10010.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing APTOS/val_images...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 15196.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing APTOS/test_images...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 17697.49it/s]\n"
          ]
        }
      ],
      "source": [
        "preprocess_dataset('APTOS/train_images')\n",
        "preprocess_dataset('APTOS/val_images')\n",
        "preprocess_dataset('APTOS/test_images')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lc0cS8Ybdai9",
        "outputId": "b564d963-db41-4266-f0bf-f595aabab5b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔄 Moving files from /content/drive/MyDrive/retinalnewproject/datasets/ODIR5K/datasets to /content/drive/MyDrive/retinalnewproject/datasets/ODIR5K ...\n",
            "✅ Moved files for ODIR5K\n",
            "⚠️ No inner 'datasets' folder found for RFMiD, skipping.\n",
            "⚠️ No inner 'datasets' folder found for APTOS, skipping.\n",
            "⚠️ No inner 'datasets' folder found for Messidor2, skipping.\n",
            "⚠️ No inner 'datasets' folder found for DRIVE, skipping.\n",
            "⚠️ No inner 'datasets' folder found for CHASEDB1, skipping.\n"
          ]
        }
      ],
      "source": [
        "import os, shutil\n",
        "\n",
        "# Base folder where your datasets are stored\n",
        "BASE_PATH = \"/content/drive/MyDrive/retinalnewproject/datasets\"\n",
        "\n",
        "# List of datasets you downloaded\n",
        "DATASETS = [\"ODIR5K\",\"RFMiD\",\"APTOS\",\"Messidor2\",\"DRIVE\",\"CHASEDB1\"]\n",
        "\n",
        "for ds in DATASETS:\n",
        "    inner_path = os.path.join(BASE_PATH, ds, \"datasets\")  # The extra nested folder\n",
        "    outer_path = os.path.join(BASE_PATH, ds)\n",
        "\n",
        "    if os.path.exists(inner_path):\n",
        "        print(f\"🔄 Moving files from {inner_path} to {outer_path} ...\")\n",
        "        for root, _, files in os.walk(inner_path):\n",
        "            for f in files:\n",
        "                src = os.path.join(root, f)\n",
        "                dst = os.path.join(outer_path, f)\n",
        "                if not os.path.exists(dst):   # Avoid overwriting\n",
        "                    shutil.move(src, dst)\n",
        "        print(f\"✅ Moved files for {ds}\")\n",
        "    else:\n",
        "        print(f\"⚠️ No inner 'datasets' folder found for {ds}, skipping.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "base_path = \"/content/drive/MyDrive/retinalnewproject\"\n",
        "print(os.listdir(base_path))\n"
      ],
      "metadata": {
        "id": "bRRs5VvgNjYm",
        "outputId": "0f06f1c1-b6dd-496e-90ad-40a806b75604",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['datasets', 'outputs', 'reports', 'preprocessing', 'segmentation', 'federated', 'ensemble', 'results']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "datasets_path = \"/content/drive/MyDrive/retinalnewproject/datasets\"\n",
        "print(os.listdir(datasets_path))\n"
      ],
      "metadata": {
        "id": "gpkQe5QqNwdX",
        "outputId": "e6e7dd1c-fc12-4932-cab6-4985e9e10b88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['DRIVE', '.ipynb_checkpoints', 'APTOS', 'CHASEDB1', 'Messidor2', 'ODIR5K', 'RFMiD']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"/content/drive/MyDrive/retinalnewproject/preprocessing/APTOS\"\n"
      ],
      "metadata": {
        "id": "oEGrDwPbOBXu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(validation_split=0.2, rescale=1./255)\n",
        "\n",
        "train_gen = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224,224),   # can use 512x512 if GPU is strong\n",
        "    batch_size=16,\n",
        "    subset='training',\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_gen = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224,224),\n",
        "    batch_size=16,\n",
        "    subset='validation',\n",
        "    class_mode='categorical'\n",
        ")\n"
      ],
      "metadata": {
        "id": "J-JLGzR8OD7P",
        "outputId": "198fbb2d-c61d-422a-ae86-20c174385e71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 images belonging to 0 classes.\n",
            "Found 0 images belonging to 0 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python tensorflow torch torchvision tqdm matplotlib scikit-learn\n"
      ],
      "metadata": {
        "id": "jR94T6U4OW_Q",
        "outputId": "59616af9-e415-4571-817c-333e56391da9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.74.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "https://github.com/israinamdar493-ops/retinalprojectsizz4/blob/main/Retinalai.ipynb",
      "authorship_tag": "ABX9TyMGl1imV4BFMUlJb7wH3yd5",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}