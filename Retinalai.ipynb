{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/israinamdar493-ops/retinalprojectsizz4/blob/main/Retinalai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zs8re2pbFoKX",
        "outputId": "e8f0231a-4ca2-4789-f93a-a9229a95f9b0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 4044.65it/s]\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "input_folder = '/content/drive/MyDrive/retinalnewproject/datasets/odir5k'\n",
        "output_folder = '/content/drive/MyDrive/retinalnewproject/outputs'\n",
        "\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "for file in tqdm(os.listdir(input_folder)):\n",
        "    if file.endswith(\".jpg\") or file.endswith(\".png\"):\n",
        "        img = cv2.imread(os.path.join(input_folder, file))\n",
        "        img_resized = cv2.resize(img, (512,512))\n",
        "        cv2.imwrite(os.path.join(output_folder, file), img_resized)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uu92Byhlwri5"
      },
      "outputs": [],
      "source": [
        "# Example: read image and normalize\n",
        "img = cv2.imread('/content/drive/MyDrive/retinalnewproject/datasets/odir5k/datasets/ageDegeneration/image0.png')\n",
        "img_normalized = img / 255.0  # now pixel values are between 0 and 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WawGv4FCznEI"
      },
      "outputs": [],
      "source": [
        "def augment_image(img):\n",
        "    import cv2\n",
        "    import numpy as np\n",
        "\n",
        "    # 1. Horizontal flip\n",
        "    img_flip = cv2.flip(img, 1)\n",
        "\n",
        "    # 2. Rotation (90 degrees)\n",
        "    img_rot = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
        "\n",
        "    # 3. CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
        "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
        "    l, a, b = cv2.split(lab)\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "    cl = clahe.apply(l)\n",
        "    lab_clahe = cv2.merge((cl,a,b))\n",
        "    img_clahe = cv2.cvtColor(lab_clahe, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    return [img_flip, img_rot, img_clahe]\n",
        "\n",
        "# Example usage\n",
        "augmented_images = augment_image(img)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5pJnBhVzsv9",
        "outputId": "7179078f-3142-4ad0-bae1-f57888d7114c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 3057.07it/s]\n"
          ]
        }
      ],
      "source": [
        "for file in tqdm(os.listdir(input_folder)):\n",
        "    if file.endswith(\".jpg\") or file.endswith(\".png\"):\n",
        "        img = cv2.imread(os.path.join(input_folder, file))\n",
        "        aug_imgs = augment_image(img)\n",
        "        # Save augmented images\n",
        "        for i, aug in enumerate(aug_imgs):\n",
        "            filename = file.split('.')[0] + f'_aug{i}.jpg'\n",
        "            cv2.imwrite(os.path.join(output_folder, filename), aug)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMoJn8g60NwW",
        "outputId": "30e42034-fb17-46ca-8152-d03306d0d8f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing ODIR5K...\n",
            "âœ… Finished ODIR5K\n",
            "\n",
            "Processing RFMiD...\n",
            "âœ… Finished RFMiD\n",
            "\n",
            "Processing APTOS...\n",
            "âœ… Finished APTOS\n",
            "\n",
            "Processing Messidor2...\n",
            "âœ… Finished Messidor2\n",
            "\n",
            "Processing DRIVE...\n",
            "âœ… Finished DRIVE\n",
            "\n",
            "Processing CHASEDB1...\n",
            "âœ… Finished CHASEDB1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import cv2, os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Your dataset names\n",
        "DATASETS = ['ODIR5K', 'RFMiD', 'APTOS', 'Messidor2', 'DRIVE', 'CHASEDB1']\n",
        "\n",
        "# Set paths\n",
        "base_path = \"/content/drive/MyDrive/retinalnewproject/datasets\"\n",
        "output_base = \"/content/drive/MyDrive/retinalnewproject/preprocessing\"\n",
        "resize_dim = (512, 512)  # Resize to 512x512\n",
        "\n",
        "def augment_image(img):\n",
        "    \"\"\"Basic data augmentation\"\"\"\n",
        "    aug_list = []\n",
        "    aug_list.append(cv2.flip(img, 1))                        # Horizontal flip\n",
        "    aug_list.append(cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)) # Rotate 90\n",
        "    return aug_list\n",
        "\n",
        "def preprocess_dataset(dataset):\n",
        "    input_folder = os.path.join(base_path, dataset)\n",
        "    output_folder = os.path.join(output_base, dataset)\n",
        "\n",
        "    if not os.path.exists(input_folder):\n",
        "        print(f\"âš ï¸ Skipping {dataset}: Input folder not found.\")\n",
        "        return\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    print(f\"Processing {dataset}...\")\n",
        "\n",
        "    # âœ… This walks through all subfolders to find images\n",
        "    for root, _, files in os.walk(input_folder):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
        "                img_path = os.path.join(root, file)\n",
        "                img = cv2.imread(img_path)\n",
        "\n",
        "                if img is None:  # Skip if image can't be read\n",
        "                    continue\n",
        "\n",
        "                # Resize and normalize\n",
        "                img_resized = cv2.resize(img, resize_dim)\n",
        "                img_normalized = img_resized / 255.0\n",
        "\n",
        "                # Save resized image\n",
        "                save_path = os.path.join(output_folder, file)\n",
        "                cv2.imwrite(save_path, (img_normalized * 255).astype(np.uint8))\n",
        "\n",
        "                # Data augmentation\n",
        "                for i, aug in enumerate(augment_image(img_resized)):\n",
        "                    aug_name = file.split('.')[0] + f'_aug{i}.jpg'\n",
        "                    cv2.imwrite(os.path.join(output_folder, aug_name), aug)\n",
        "\n",
        "    print(f\"âœ… Finished {dataset}\\n\")\n",
        "\n",
        "# Run preprocessing for all datasets\n",
        "for dataset in DATASETS:\n",
        "    preprocess_dataset(dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8q0gJ_K9ckyg",
        "outputId": "21b38260-6c6d-4047-d0e8-9cde021dd72b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files inside ODIR5K: ['test.csv', 'train_1.csv', 'valid.csv', 'val_images', 'train_images', 'test_images']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "path = \"/content/drive/MyDrive/retinalnewproject/datasets/APTOS\"\n",
        "print(\"Files inside ODIR5K:\", os.listdir(path))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a52AMU8AgTuG",
        "outputId": "6f4456cd-7b58-4456-8562-43a3bafb9a8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing APTOS/train_images...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 10010.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing APTOS/val_images...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15196.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing APTOS/test_images...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17697.49it/s]\n"
          ]
        }
      ],
      "source": [
        "preprocess_dataset('APTOS/train_images')\n",
        "preprocess_dataset('APTOS/val_images')\n",
        "preprocess_dataset('APTOS/test_images')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lc0cS8Ybdai9",
        "outputId": "b564d963-db41-4266-f0bf-f595aabab5b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ”„ Moving files from /content/drive/MyDrive/retinalnewproject/datasets/ODIR5K/datasets to /content/drive/MyDrive/retinalnewproject/datasets/ODIR5K ...\n",
            "âœ… Moved files for ODIR5K\n",
            "âš ï¸ No inner 'datasets' folder found for RFMiD, skipping.\n",
            "âš ï¸ No inner 'datasets' folder found for APTOS, skipping.\n",
            "âš ï¸ No inner 'datasets' folder found for Messidor2, skipping.\n",
            "âš ï¸ No inner 'datasets' folder found for DRIVE, skipping.\n",
            "âš ï¸ No inner 'datasets' folder found for CHASEDB1, skipping.\n"
          ]
        }
      ],
      "source": [
        "import os, shutil\n",
        "\n",
        "# Base folder where your datasets are stored\n",
        "BASE_PATH = \"/content/drive/MyDrive/retinalnewproject/datasets\"\n",
        "\n",
        "# List of datasets you downloaded\n",
        "DATASETS = [\"ODIR5K\",\"RFMiD\",\"APTOS\",\"Messidor2\",\"DRIVE\",\"CHASEDB1\"]\n",
        "\n",
        "for ds in DATASETS:\n",
        "    inner_path = os.path.join(BASE_PATH, ds, \"datasets\")  # The extra nested folder\n",
        "    outer_path = os.path.join(BASE_PATH, ds)\n",
        "\n",
        "    if os.path.exists(inner_path):\n",
        "        print(f\"ðŸ”„ Moving files from {inner_path} to {outer_path} ...\")\n",
        "        for root, _, files in os.walk(inner_path):\n",
        "            for f in files:\n",
        "                src = os.path.join(root, f)\n",
        "                dst = os.path.join(outer_path, f)\n",
        "                if not os.path.exists(dst):   # Avoid overwriting\n",
        "                    shutil.move(src, dst)\n",
        "        print(f\"âœ… Moved files for {ds}\")\n",
        "    else:\n",
        "        print(f\"âš ï¸ No inner 'datasets' folder found for {ds}, skipping.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "13uXMXbhQ5yarmr_K1EG1fSYS36WEOxb3",
      "authorship_tag": "ABX9TyM9JvmnQNXCWBHBXMzCybi0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}