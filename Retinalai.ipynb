{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/israinamdar493-ops/retinalprojectsizz4/blob/main/Retinalai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zs8re2pbFoKX",
        "outputId": "e8f0231a-4ca2-4789-f93a-a9229a95f9b0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 4044.65it/s]\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "input_folder = '/content/drive/MyDrive/retinalnewproject/datasets/odir5k'\n",
        "output_folder = '/content/drive/MyDrive/retinalnewproject/outputs'\n",
        "\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "for file in tqdm(os.listdir(input_folder)):\n",
        "    if file.endswith(\".jpg\") or file.endswith(\".png\"):\n",
        "        img = cv2.imread(os.path.join(input_folder, file))\n",
        "        img_resized = cv2.resize(img, (512,512))\n",
        "        cv2.imwrite(os.path.join(output_folder, file), img_resized)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uu92Byhlwri5"
      },
      "outputs": [],
      "source": [
        "# Example: read image and normalize\n",
        "img = cv2.imread('/content/drive/MyDrive/retinalnewproject/datasets/odir5k/datasets/ageDegeneration/image0.png')\n",
        "img_normalized = img / 255.0  # now pixel values are between 0 and 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WawGv4FCznEI"
      },
      "outputs": [],
      "source": [
        "def augment_image(img):\n",
        "    import cv2\n",
        "    import numpy as np\n",
        "\n",
        "    # 1. Horizontal flip\n",
        "    img_flip = cv2.flip(img, 1)\n",
        "\n",
        "    # 2. Rotation (90 degrees)\n",
        "    img_rot = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
        "\n",
        "    # 3. CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
        "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
        "    l, a, b = cv2.split(lab)\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "    cl = clahe.apply(l)\n",
        "    lab_clahe = cv2.merge((cl,a,b))\n",
        "    img_clahe = cv2.cvtColor(lab_clahe, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    return [img_flip, img_rot, img_clahe]\n",
        "\n",
        "# Example usage\n",
        "augmented_images = augment_image(img)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5pJnBhVzsv9",
        "outputId": "7179078f-3142-4ad0-bae1-f57888d7114c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 3057.07it/s]\n"
          ]
        }
      ],
      "source": [
        "for file in tqdm(os.listdir(input_folder)):\n",
        "    if file.endswith(\".jpg\") or file.endswith(\".png\"):\n",
        "        img = cv2.imread(os.path.join(input_folder, file))\n",
        "        aug_imgs = augment_image(img)\n",
        "        # Save augmented images\n",
        "        for i, aug in enumerate(aug_imgs):\n",
        "            filename = file.split('.')[0] + f'_aug{i}.jpg'\n",
        "            cv2.imwrite(os.path.join(output_folder, filename), aug)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMoJn8g60NwW",
        "outputId": "30e42034-fb17-46ca-8152-d03306d0d8f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing ODIR5K...\n",
            "âœ… Finished ODIR5K\n",
            "\n",
            "Processing RFMiD...\n",
            "âœ… Finished RFMiD\n",
            "\n",
            "Processing APTOS...\n",
            "âœ… Finished APTOS\n",
            "\n",
            "Processing Messidor2...\n",
            "âœ… Finished Messidor2\n",
            "\n",
            "Processing DRIVE...\n",
            "âœ… Finished DRIVE\n",
            "\n",
            "Processing CHASEDB1...\n",
            "âœ… Finished CHASEDB1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import cv2, os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Your dataset names\n",
        "DATASETS = ['ODIR5K', 'RFMiD', 'APTOS', 'Messidor2', 'DRIVE', 'CHASEDB1']\n",
        "\n",
        "# Set paths\n",
        "base_path = \"/content/drive/MyDrive/retinalnewproject/datasets\"\n",
        "output_base = \"/content/drive/MyDrive/retinalnewproject/preprocessing\"\n",
        "resize_dim = (512, 512)  # Resize to 512x512\n",
        "\n",
        "def augment_image(img):\n",
        "    \"\"\"Basic data augmentation\"\"\"\n",
        "    aug_list = []\n",
        "    aug_list.append(cv2.flip(img, 1))                        # Horizontal flip\n",
        "    aug_list.append(cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)) # Rotate 90\n",
        "    return aug_list\n",
        "\n",
        "def preprocess_dataset(dataset):\n",
        "    input_folder = os.path.join(base_path, dataset)\n",
        "    output_folder = os.path.join(output_base, dataset)\n",
        "\n",
        "    if not os.path.exists(input_folder):\n",
        "        print(f\"âš ï¸ Skipping {dataset}: Input folder not found.\")\n",
        "        return\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    print(f\"Processing {dataset}...\")\n",
        "\n",
        "    # âœ… This walks through all subfolders to find images\n",
        "    for root, _, files in os.walk(input_folder):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
        "                img_path = os.path.join(root, file)\n",
        "                img = cv2.imread(img_path)\n",
        "\n",
        "                if img is None:  # Skip if image can't be read\n",
        "                    continue\n",
        "\n",
        "                # Resize and normalize\n",
        "                img_resized = cv2.resize(img, resize_dim)\n",
        "                img_normalized = img_resized / 255.0\n",
        "\n",
        "                # Save resized image\n",
        "                save_path = os.path.join(output_folder, file)\n",
        "                cv2.imwrite(save_path, (img_normalized * 255).astype(np.uint8))\n",
        "\n",
        "                # Data augmentation\n",
        "                for i, aug in enumerate(augment_image(img_resized)):\n",
        "                    aug_name = file.split('.')[0] + f'_aug{i}.jpg'\n",
        "                    cv2.imwrite(os.path.join(output_folder, aug_name), aug)\n",
        "\n",
        "    print(f\"âœ… Finished {dataset}\\n\")\n",
        "\n",
        "# Run preprocessing for all datasets\n",
        "for dataset in DATASETS:\n",
        "    preprocess_dataset(dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8q0gJ_K9ckyg",
        "outputId": "21b38260-6c6d-4047-d0e8-9cde021dd72b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files inside ODIR5K: ['test.csv', 'train_1.csv', 'valid.csv', 'val_images', 'train_images', 'test_images']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "path = \"/content/drive/MyDrive/retinalnewproject/datasets/APTOS\"\n",
        "print(\"Files inside ODIR5K:\", os.listdir(path))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a52AMU8AgTuG",
        "outputId": "6f4456cd-7b58-4456-8562-43a3bafb9a8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing APTOS/train_images...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 10010.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing APTOS/val_images...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15196.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing APTOS/test_images...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17697.49it/s]\n"
          ]
        }
      ],
      "source": [
        "preprocess_dataset('APTOS/train_images')\n",
        "preprocess_dataset('APTOS/val_images')\n",
        "preprocess_dataset('APTOS/test_images')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lc0cS8Ybdai9",
        "outputId": "b564d963-db41-4266-f0bf-f595aabab5b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ”„ Moving files from /content/drive/MyDrive/retinalnewproject/datasets/ODIR5K/datasets to /content/drive/MyDrive/retinalnewproject/datasets/ODIR5K ...\n",
            "âœ… Moved files for ODIR5K\n",
            "âš ï¸ No inner 'datasets' folder found for RFMiD, skipping.\n",
            "âš ï¸ No inner 'datasets' folder found for APTOS, skipping.\n",
            "âš ï¸ No inner 'datasets' folder found for Messidor2, skipping.\n",
            "âš ï¸ No inner 'datasets' folder found for DRIVE, skipping.\n",
            "âš ï¸ No inner 'datasets' folder found for CHASEDB1, skipping.\n"
          ]
        }
      ],
      "source": [
        "import os, shutil\n",
        "\n",
        "# Base folder where your datasets are stored\n",
        "BASE_PATH = \"/content/drive/MyDrive/retinalnewproject/datasets\"\n",
        "\n",
        "# List of datasets you downloaded\n",
        "DATASETS = [\"ODIR5K\",\"RFMiD\",\"APTOS\",\"Messidor2\",\"DRIVE\",\"CHASEDB1\"]\n",
        "\n",
        "for ds in DATASETS:\n",
        "    inner_path = os.path.join(BASE_PATH, ds, \"datasets\")  # The extra nested folder\n",
        "    outer_path = os.path.join(BASE_PATH, ds)\n",
        "\n",
        "    if os.path.exists(inner_path):\n",
        "        print(f\"ðŸ”„ Moving files from {inner_path} to {outer_path} ...\")\n",
        "        for root, _, files in os.walk(inner_path):\n",
        "            for f in files:\n",
        "                src = os.path.join(root, f)\n",
        "                dst = os.path.join(outer_path, f)\n",
        "                if not os.path.exists(dst):   # Avoid overwriting\n",
        "                    shutil.move(src, dst)\n",
        "        print(f\"âœ… Moved files for {ds}\")\n",
        "    else:\n",
        "        print(f\"âš ï¸ No inner 'datasets' folder found for {ds}, skipping.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "base_path = \"/content/drive/MyDrive/retinalnewproject\"\n",
        "print(os.listdir(base_path))\n"
      ],
      "metadata": {
        "id": "bRRs5VvgNjYm",
        "outputId": "0f06f1c1-b6dd-496e-90ad-40a806b75604",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['datasets', 'outputs', 'reports', 'preprocessing', 'segmentation', 'federated', 'ensemble', 'results']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "datasets_path = \"/content/drive/MyDrive/retinalnewproject/datasets\"\n",
        "print(os.listdir(datasets_path))\n"
      ],
      "metadata": {
        "id": "gpkQe5QqNwdX",
        "outputId": "e6e7dd1c-fc12-4932-cab6-4985e9e10b88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['DRIVE', '.ipynb_checkpoints', 'APTOS', 'CHASEDB1', 'Messidor2', 'ODIR5K', 'RFMiD']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"/content/drive/MyDrive/retinalnewproject/preprocessing/APTOS\"\n"
      ],
      "metadata": {
        "id": "oEGrDwPbOBXu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(validation_split=0.2, rescale=1./255)\n",
        "\n",
        "train_gen = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224,224),   # can use 512x512 if GPU is strong\n",
        "    batch_size=16,\n",
        "    subset='training',\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_gen = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224,224),\n",
        "    batch_size=16,\n",
        "    subset='validation',\n",
        "    class_mode='categorical'\n",
        ")\n"
      ],
      "metadata": {
        "id": "J-JLGzR8OD7P",
        "outputId": "198fbb2d-c61d-422a-ae86-20c174385e71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 images belonging to 0 classes.\n",
            "Found 0 images belonging to 0 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python tensorflow torch torchvision tqdm matplotlib scikit-learn\n"
      ],
      "metadata": {
        "id": "jR94T6U4OW_Q",
        "outputId": "59616af9-e415-4571-817c-333e56391da9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.74.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "https://github.com/israinamdar493-ops/retinalprojectsizz4/blob/main/Retinalai.ipynb",
      "authorship_tag": "ABX9TyMGl1imV4BFMUlJb7wH3yd5",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}