{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/israinamdar493-ops/retinalprojectsizz4/blob/main/Retinalai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zs8re2pbFoKX",
        "outputId": "e8f0231a-4ca2-4789-f93a-a9229a95f9b0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 4044.65it/s]\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "input_folder = '/content/drive/MyDrive/retinalnewproject/datasets/odir5k'\n",
        "output_folder = '/content/drive/MyDrive/retinalnewproject/outputs'\n",
        "\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "for file in tqdm(os.listdir(input_folder)):\n",
        "    if file.endswith(\".jpg\") or file.endswith(\".png\"):\n",
        "        img = cv2.imread(os.path.join(input_folder, file))\n",
        "        img_resized = cv2.resize(img, (512,512))\n",
        "        cv2.imwrite(os.path.join(output_folder, file), img_resized)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uu92Byhlwri5"
      },
      "outputs": [],
      "source": [
        "# Example: read image and normalize\n",
        "img = cv2.imread('/content/drive/MyDrive/retinalnewproject/datasets/odir5k/datasets/ageDegeneration/image0.png')\n",
        "img_normalized = img / 255.0  # now pixel values are between 0 and 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WawGv4FCznEI"
      },
      "outputs": [],
      "source": [
        "def augment_image(img):\n",
        "    import cv2\n",
        "    import numpy as np\n",
        "\n",
        "    # 1. Horizontal flip\n",
        "    img_flip = cv2.flip(img, 1)\n",
        "\n",
        "    # 2. Rotation (90 degrees)\n",
        "    img_rot = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
        "\n",
        "    # 3. CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
        "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
        "    l, a, b = cv2.split(lab)\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "    cl = clahe.apply(l)\n",
        "    lab_clahe = cv2.merge((cl,a,b))\n",
        "    img_clahe = cv2.cvtColor(lab_clahe, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    return [img_flip, img_rot, img_clahe]\n",
        "\n",
        "# Example usage\n",
        "augmented_images = augment_image(img)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5pJnBhVzsv9",
        "outputId": "7179078f-3142-4ad0-bae1-f57888d7114c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 3057.07it/s]\n"
          ]
        }
      ],
      "source": [
        "for file in tqdm(os.listdir(input_folder)):\n",
        "    if file.endswith(\".jpg\") or file.endswith(\".png\"):\n",
        "        img = cv2.imread(os.path.join(input_folder, file))\n",
        "        aug_imgs = augment_image(img)\n",
        "        # Save augmented images\n",
        "        for i, aug in enumerate(aug_imgs):\n",
        "            filename = file.split('.')[0] + f'_aug{i}.jpg'\n",
        "            cv2.imwrite(os.path.join(output_folder, filename), aug)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMoJn8g60NwW",
        "outputId": "30e42034-fb17-46ca-8152-d03306d0d8f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing ODIR5K...\n",
            "✅ Finished ODIR5K\n",
            "\n",
            "Processing RFMiD...\n",
            "✅ Finished RFMiD\n",
            "\n",
            "Processing APTOS...\n",
            "✅ Finished APTOS\n",
            "\n",
            "Processing Messidor2...\n",
            "✅ Finished Messidor2\n",
            "\n",
            "Processing DRIVE...\n",
            "✅ Finished DRIVE\n",
            "\n",
            "Processing CHASEDB1...\n",
            "✅ Finished CHASEDB1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import cv2, os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Your dataset names\n",
        "DATASETS = ['ODIR5K', 'RFMiD', 'APTOS', 'Messidor2', 'DRIVE', 'CHASEDB1']\n",
        "\n",
        "# Set paths\n",
        "base_path = \"/content/drive/MyDrive/retinalnewproject/datasets\"\n",
        "output_base = \"/content/drive/MyDrive/retinalnewproject/preprocessing\"\n",
        "resize_dim = (512, 512)  # Resize to 512x512\n",
        "\n",
        "def augment_image(img):\n",
        "    \"\"\"Basic data augmentation\"\"\"\n",
        "    aug_list = []\n",
        "    aug_list.append(cv2.flip(img, 1))                        # Horizontal flip\n",
        "    aug_list.append(cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)) # Rotate 90\n",
        "    return aug_list\n",
        "\n",
        "def preprocess_dataset(dataset):\n",
        "    input_folder = os.path.join(base_path, dataset)\n",
        "    output_folder = os.path.join(output_base, dataset)\n",
        "\n",
        "    if not os.path.exists(input_folder):\n",
        "        print(f\"⚠️ Skipping {dataset}: Input folder not found.\")\n",
        "        return\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    print(f\"Processing {dataset}...\")\n",
        "\n",
        "    # ✅ This walks through all subfolders to find images\n",
        "    for root, _, files in os.walk(input_folder):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
        "                img_path = os.path.join(root, file)\n",
        "                img = cv2.imread(img_path)\n",
        "\n",
        "                if img is None:  # Skip if image can't be read\n",
        "                    continue\n",
        "\n",
        "                # Resize and normalize\n",
        "                img_resized = cv2.resize(img, resize_dim)\n",
        "                img_normalized = img_resized / 255.0\n",
        "\n",
        "                # Save resized image\n",
        "                save_path = os.path.join(output_folder, file)\n",
        "                cv2.imwrite(save_path, (img_normalized * 255).astype(np.uint8))\n",
        "\n",
        "                # Data augmentation\n",
        "                for i, aug in enumerate(augment_image(img_resized)):\n",
        "                    aug_name = file.split('.')[0] + f'_aug{i}.jpg'\n",
        "                    cv2.imwrite(os.path.join(output_folder, aug_name), aug)\n",
        "\n",
        "    print(f\"✅ Finished {dataset}\\n\")\n",
        "\n",
        "# Run preprocessing for all datasets\n",
        "for dataset in DATASETS:\n",
        "    preprocess_dataset(dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8q0gJ_K9ckyg",
        "outputId": "21b38260-6c6d-4047-d0e8-9cde021dd72b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files inside ODIR5K: ['test.csv', 'train_1.csv', 'valid.csv', 'val_images', 'train_images', 'test_images']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "path = \"/content/drive/MyDrive/retinalnewproject/datasets/APTOS\"\n",
        "print(\"Files inside ODIR5K:\", os.listdir(path))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a52AMU8AgTuG",
        "outputId": "6f4456cd-7b58-4456-8562-43a3bafb9a8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing APTOS/train_images...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 10010.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing APTOS/val_images...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 15196.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing APTOS/test_images...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 17697.49it/s]\n"
          ]
        }
      ],
      "source": [
        "preprocess_dataset('APTOS/train_images')\n",
        "preprocess_dataset('APTOS/val_images')\n",
        "preprocess_dataset('APTOS/test_images')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lc0cS8Ybdai9",
        "outputId": "b564d963-db41-4266-f0bf-f595aabab5b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔄 Moving files from /content/drive/MyDrive/retinalnewproject/datasets/ODIR5K/datasets to /content/drive/MyDrive/retinalnewproject/datasets/ODIR5K ...\n",
            "✅ Moved files for ODIR5K\n",
            "⚠️ No inner 'datasets' folder found for RFMiD, skipping.\n",
            "⚠️ No inner 'datasets' folder found for APTOS, skipping.\n",
            "⚠️ No inner 'datasets' folder found for Messidor2, skipping.\n",
            "⚠️ No inner 'datasets' folder found for DRIVE, skipping.\n",
            "⚠️ No inner 'datasets' folder found for CHASEDB1, skipping.\n"
          ]
        }
      ],
      "source": [
        "import os, shutil\n",
        "\n",
        "# Base folder where your datasets are stored\n",
        "BASE_PATH = \"/content/drive/MyDrive/retinalnewproject/datasets\"\n",
        "\n",
        "# List of datasets you downloaded\n",
        "DATASETS = [\"ODIR5K\",\"RFMiD\",\"APTOS\",\"Messidor2\",\"DRIVE\",\"CHASEDB1\"]\n",
        "\n",
        "for ds in DATASETS:\n",
        "    inner_path = os.path.join(BASE_PATH, ds, \"datasets\")  # The extra nested folder\n",
        "    outer_path = os.path.join(BASE_PATH, ds)\n",
        "\n",
        "    if os.path.exists(inner_path):\n",
        "        print(f\"🔄 Moving files from {inner_path} to {outer_path} ...\")\n",
        "        for root, _, files in os.walk(inner_path):\n",
        "            for f in files:\n",
        "                src = os.path.join(root, f)\n",
        "                dst = os.path.join(outer_path, f)\n",
        "                if not os.path.exists(dst):   # Avoid overwriting\n",
        "                    shutil.move(src, dst)\n",
        "        print(f\"✅ Moved files for {ds}\")\n",
        "    else:\n",
        "        print(f\"⚠️ No inner 'datasets' folder found for {ds}, skipping.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "13uXMXbhQ5yarmr_K1EG1fSYS36WEOxb3",
      "authorship_tag": "ABX9TyM9JvmnQNXCWBHBXMzCybi0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}